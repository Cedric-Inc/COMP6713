{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQJFyL8/hoSI3Q6Gb9k/OM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"S9yzseVZu0jc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745669690232,"user_tz":-600,"elapsed":674974,"user":{"displayName":"Xiao Chen","userId":"01844061049952599258"}},"outputId":"c140d74f-3204-442d-fc0a-f0f83a7dd229"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["Generating with GPT: 100%|██████████| 1355/1355 [11:13<00:00,  2.01it/s]\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from openai import OpenAI\n","import pandas as pd\n","import time\n","from tqdm import tqdm\n","import json\n","\n","\n","client = OpenAI(api_key=\"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\")\n","\n","MODEL = \"gpt-3.5-turbo\"\n","\n","def gpt_call(prompt, max_tokens=128, temperature=0.0, retries=3, delay=2):\n","    for _ in range(retries):\n","        try:\n","            start = time.time()\n","            response = client.chat.completions.create(\n","                model=MODEL,\n","                messages=[\n","                    {\"role\": \"user\", \"content\": prompt}\n","                ],\n","                max_tokens=max_tokens,\n","                temperature=temperature\n","            )\n","            elapsed = time.time() - start\n","            return response.choices[0].message.content.strip(), elapsed\n","        except Exception as e:\n","            print(f\"Error: {e}, retrying in {delay}s...\")\n","            time.sleep(delay)\n","    return \"API_ERROR\", 0.0\n","\n","with open(\"/content/drive/MyDrive/AdSeek/Preprocessing/p_engineering_testsets/p_engineering_testset.json\", \"r\", encoding=\"utf-8\") as f:\n","    data = json.load(f)\n","\n","df = pd.DataFrame(data)\n","\n","# df = pd.concat([\n","#     df.iloc[:10],\n","#     df.iloc[600:610],\n","#     df.iloc[-10:]\n","# ], ignore_index=True)\n","\n","df['prompt'] = df['prompt'].fillna(\"\").astype(str)\n","\n","\n","responses = []\n","inference_times = []\n","\n","for prompt in tqdm(df['prompt'], desc=\"Generating with GPT\"):\n","    result, t = gpt_call(prompt)\n","    responses.append(result)\n","    inference_times.append(t)\n","\n","df['y_pred'] = responses\n","df['inference_time'] = inference_times\n","\n","output_path = \"gpt_predictions_openai1.json\"\n","df.to_json(output_path, orient=\"records\", force_ascii=False, indent=2)"]},{"cell_type":"code","source":[],"metadata":{"id":"HCMLkX3c5qBb"},"execution_count":null,"outputs":[]}]}