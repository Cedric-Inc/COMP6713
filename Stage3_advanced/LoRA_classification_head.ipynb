{"cells":[{"cell_type":"code","execution_count":null,"id":"d2d30b45","metadata":{"vscode":{"languageId":"plaintext"},"id":"d2d30b45"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"ea2ad9a3","metadata":{"vscode":{"languageId":"plaintext"},"id":"ea2ad9a3"},"outputs":[],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"id":"64e24c99","metadata":{"vscode":{"languageId":"plaintext"},"id":"64e24c99"},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","import torch, torch.nn as nn\n","from transformers import TrainingArguments\n","\n","BASE = \"Qwen/Qwen2.5-0.5B-Instruct\"\n","\n","tok  = AutoTokenizer.from_pretrained(BASE, trust_remote_code=True)\n","lm   = AutoModelForCausalLM.from_pretrained(\n","        BASE, torch_dtype=torch.bfloat16, trust_remote_code=True,\n","        device_map=\"auto\")\n","\n","\n","lm = prepare_model_for_kbit_training(lm)          # 4bit + grad_ckpt\n","\n","lora_cfg = LoraConfig(\n","    r=4, lora_alpha=16,\n","    target_modules = [\n","    f\"layers.{i}.self_attn.{proj}\"\n","    for i in range(20, 24)\n","    for proj in (\"q_proj\", \"v_proj\")\n","],\n","    lora_dropout=0.05, task_type=\"CAUSAL_LM\")\n","lm = get_peft_model(lm, lora_cfg)"]},{"cell_type":"code","execution_count":null,"id":"acb79f8e","metadata":{"vscode":{"languageId":"plaintext"},"id":"acb79f8e"},"outputs":[],"source":["LABELS = [\"Onsite\", \"Remote\", \"Hybrid\"]\n","NUM    = len(LABELS)\n","\n","class MultiTaskQwen(nn.Module):\n","    def __init__(self, base_lm, tokenizer, labels):\n","        super().__init__()\n","        self.lm  = base_lm\n","        self.tok = tokenizer\n","        self.labels = labels\n","\n","        hs = base_lm.config.hidden_size\n","        self.class_head = nn.Linear(hs, len(labels))\n","        self.id2vec     = nn.Embedding(len(labels), hs)\n","\n","        self.label_tok_ids = [tokenizer(l, add_special_tokens=False)[\"input_ids\"]\n","                              for l in labels]\n","\n","    def forward(self,\n","        input_ids,\n","        attention_mask,\n","        labels      = None,\n","        cls_labels     = None,\n","        task_type_id  = None,\n","        lambda_cls=1.0,\n","        lambda_gen=1.0):\n","\n","        outputs = self.lm.model(\n","            input_ids, attention_mask,\n","            output_hidden_states=True, use_cache=False\n","        )\n","        h_last = outputs.hidden_states[-1]     # (B,L,H)\n","\n","        cls_loss = torch.tensor(0., device=h_last.device)\n","        if task_type_id is not None and (task_type_id == 1).any():\n","            eos_idx = (input_ids != self.tok.pad_token_id).sum(-1) - 1  # (B,)\n","            seq_repr = h_last[torch.arange(h_last.size(0)), eos_idx]\n","\n","            cls_logits = self.class_head(seq_repr)\n","            loss_fct   = nn.CrossEntropyLoss(ignore_index=-100)\n","            cls_loss   = loss_fct(cls_logits, cls_labels)\n","\n","            # Adding class embedding\n","            pred_ids = cls_logits.argmax(-1)\n","            delta    = self.id2vec(pred_ids)\n","            h_last[torch.arange(h_last.size(0)), eos_idx] += delta\n","\n","        # ---------- LM Head ----------\n","        lm_logits = self.lm.lm_head(h_last)\n","\n","        lm_loss = torch.tensor(0., device=h_last.device)\n","\n","        if labels is not None:\n","            shift_log  = lm_logits[..., :-1, :].contiguous()\n","            shift_lab  = labels[..., 1:].contiguous()\n","            loss_fct   = nn.CrossEntropyLoss(ignore_index=-100)\n","            lm_loss    = loss_fct(shift_log.view(-1, shift_log.size(-1)),\n","                                  shift_lab.view(-1))\n","\n","        total = lambda_cls * cls_loss + lambda_gen * lm_loss\n","        return {\"loss\": total, \"logits\": lm_logits}\n","model = MultiTaskQwen(lm, tok, LABELS)"]},{"cell_type":"code","execution_count":null,"id":"8e73c3d1","metadata":{"vscode":{"languageId":"plaintext"},"id":"8e73c3d1"},"outputs":[],"source":["MAX_LEN   = 1024\n","TAIL_LEN  =  128\n","HEAD_LEN  = MAX_LEN - TAIL_LEN\n","STRIDE    = 896\n","LABEL2ID  = {l: i for i, l in enumerate(LABELS)}\n","\n","def trim_keep_tail(ids):\n","    return ids if len(ids) <= MAX_LEN else ids[:HEAD_LEN] + ids[-TAIL_LEN:]\n","\n","def pad_to(ids, pad_id):\n","    pad = MAX_LEN - len(ids)\n","    return ids + [pad_id] * pad, [1] * len(ids) + [0] * pad\n","\n","def build_cls_sample(text_ids, tgt_ids, label_id):\n","    ids = trim_keep_tail(text_ids + tgt_ids)\n","\n","    ids, attn = pad_to(ids, tok.pad_token_id)\n","\n","    cut_prompt = min(len(text_ids), HEAD_LEN)\n","    lm_labels  = [-100] * cut_prompt + ids[cut_prompt:]\n","\n","    lm_labels += [-100] * (MAX_LEN - len(lm_labels))\n","    PAD_ID = tok.pad_token_id\n","    lm_labels = [ -100 if t == PAD_ID else t for t in lm_labels ]\n","\n","    if len(ids) != len(attn) or len(attn)!= len(lm_labels) or len(lm_labels) != MAX_LEN:\n","        print(f\"Warning: input_ids: {len(ids)}, attention_mask: {len(attn)}, labels: {len(lm_labels)}\")\n","\n","    return {\n","        \"input_ids\":     ids,\n","        \"attention_mask\": attn,\n","        \"labels\":        lm_labels,\n","        \"cls_labels\":    label_id,\n","        \"task_type_id\":  1,\n","    }\n","\n","def build_gen_sample(prompt_ids, chunk_ids, is_first_chunk):\n","    ids, attn = pad_to(chunk_ids, tok.pad_token_id)\n","\n","    if is_first_chunk:\n","        cut = min(len(prompt_ids), len(ids))\n","    else:\n","        cut = 0\n","\n","    lm_labels = [-100] * cut + ids[cut:]\n","    lm_labels += [-100] * (MAX_LEN - len(lm_labels))\n","    PAD_ID = tok.pad_token_id\n","    lm_labels = [ -100 if t == PAD_ID else t for t in lm_labels ]\n","\n","    if len(ids) != len(attn) or len(attn)!= len(lm_labels) or len(lm_labels) != MAX_LEN:\n","        print(f\"Warning: input_ids: {len(ids)}, attention_mask: {len(attn)}, labels: {len(lm_labels)}\")\n","\n","    return {\n","        \"input_ids\":     ids,\n","        \"attention_mask\":attn,\n","        \"labels\":        lm_labels,\n","        \"cls_labels\":    -100,\n","        \"task_type_id\":  0,\n","    }\n","\n","def encode_single(ex):\n","    task = ex[\"task_type\"].lower()\n","\n","    if task == \"work_arrangement\":\n","        text_ids  = tok(ex[\"prompt\"] + tok.eos_token)[\"input_ids\"]\n","        label_str = ex[\"complete\"].capitalize()\n","        tgt_ids   = tok(\" \" + label_str, add_special_tokens=False)[\"input_ids\"] \\\n","                    + [tok.eos_token_id]\n","        return build_cls_sample(text_ids, tgt_ids, LABEL2ID[label_str])\n","\n","    prompt_ids = tok(ex[\"prompt\"], add_special_tokens=False)[\"input_ids\"]\n","    full_ids   = tok(ex[\"prompt\"] + ex[\"complete\"] + tok.eos_token)[\"input_ids\"]\n","\n","    if len(full_ids) <= MAX_LEN:\n","        return build_gen_sample(prompt_ids, full_ids, is_first_chunk=True)\n","\n","    outs = []\n","    first = True\n","    for st in range(0, len(full_ids), STRIDE):\n","        chunk = full_ids[st : st + MAX_LEN]\n","        if len(chunk) < 128:\n","            break\n","        outs.append(build_gen_sample(prompt_ids, chunk, is_first_chunk=first))\n","        first = False\n","    return outs   # list[dict]"]},{"cell_type":"code","execution_count":null,"id":"49f6b847","metadata":{"vscode":{"languageId":"plaintext"},"id":"49f6b847"},"outputs":[],"source":["def encode_batch(batch):\n","    \"\"\"\n","    batch: dict(field→list)\n","    return: dict(field→list)\n","    \"\"\"\n","\n","    cols = {\n","        \"input_ids\": [], \"attention_mask\": [], \"labels\": [],\n","        \"cls_labels\": [], \"task_type_id\": []\n","    }\n","\n","    for p, c, t in zip(batch[\"prompt\"], batch[\"complete\"], batch[\"task_type\"]):\n","        ex = {\"prompt\": p, \"complete\": c, \"task_type\": t}\n","        res = encode_single(ex)\n","        res_list = res if isinstance(res, list) else [res]\n","\n","        for r in res_list:\n","            for k in cols:\n","                cols[k].append(r[k])\n","\n","    return cols"]},{"cell_type":"code","execution_count":null,"id":"d0ab3b63","metadata":{"vscode":{"languageId":"plaintext"},"id":"d0ab3b63"},"outputs":[],"source":["from datasets import load_dataset\n","\n","raw_ds = load_dataset(\n","    \"json\",\n","    data_files=\"./drive/MyDrive/datasetfiles/combined_prompts_completev2.json\"\n",")\n","\n","encoded_train = raw_ds[\"train\"].map(\n","    encode_batch,\n","    batched=True,\n","    batch_size= 512,\n","    remove_columns=raw_ds[\"train\"].column_names\n",")"]},{"cell_type":"code","execution_count":null,"id":"d3f8b4b0","metadata":{"vscode":{"languageId":"plaintext"},"id":"d3f8b4b0"},"outputs":[],"source":["class MultiTaskCollator:\n","    def __init__(self, tok, label_pad=-100):\n","        self.tok = tok\n","        self.label_pad = label_pad\n","\n","    def __call__(self, feats):\n","        keys = {\"input_ids\", \"attention_mask\", \"labels\",\n","                \"cls_labels\", \"task_type_id\"}\n","        for f in feats:\n","            for k in keys:\n","                if k not in f:\n","                    f[k] = [] if k in {\"input_ids\",\"attention_mask\",\"labels\"} else -100\n","\n","        max_len = max(len(f[\"input_ids\"]) for f in feats)\n","\n","        seq_keys = {\"input_ids\", \"attention_mask\", \"labels\"}\n","        batch = {}\n","        for k in keys:\n","            if k in seq_keys:\n","                pad_id = self.label_pad if k==\"labels\" else self.tok.pad_token_id\n","                batch[k] = torch.tensor(\n","                    [f[k] + [pad_id]*(max_len-len(f[k])) for f in feats],\n","                    dtype=torch.long)\n","            else:\n","                batch[k] = torch.tensor([f[k] for f in feats], dtype=torch.long)\n","\n","        return batch\n","collate = MultiTaskCollator(tok=tok, label_pad=-100)"]},{"cell_type":"code","execution_count":null,"id":"01e1624e","metadata":{"vscode":{"languageId":"plaintext"},"id":"01e1624e"},"outputs":[],"source":["\n","for n, p in model.named_parameters():\n","    p.requires_grad_(False)\n","\n","for p in model.class_head.parameters(): p.requires_grad_(True)\n","for p in model.id2vec.parameters():    p.requires_grad_(True)\n","\n","for n,p in model.named_parameters():\n","    if \"lora_\" in n: p.requires_grad_(True)\n","\n","args1 = TrainingArguments(\n","    \"./stage1_cls\",\n","    per_device_train_batch_size=4, num_train_epochs=2,\n","    learning_rate=5e-7, logging_steps=20, fp16=True, report_to=\"none\",\n","    save_safetensors  = False, save_strategy     = \"no\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"5fb90bba","metadata":{"vscode":{"languageId":"plaintext"},"id":"5fb90bba"},"outputs":[],"source":["cls_ds = encoded_train.filter(lambda ex: ex[\"task_type_id\"] == 1, load_from_cache_file=False)\n","# print(cls_ds)"]},{"cell_type":"code","execution_count":null,"id":"02230a51","metadata":{"vscode":{"languageId":"plaintext"},"id":"02230a51"},"outputs":[],"source":["from transformers import Trainer\n","\n","class MultiTaskTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None): # Add num_items_in_batch\n","\n","        out = model(**inputs,\n","                    lambda_cls=1.0,\n","                    lambda_gen=0.0)\n","        loss = out[\"loss\"]\n","        return (loss, out) if return_outputs else loss"]},{"cell_type":"code","execution_count":null,"id":"c4283e9d","metadata":{"vscode":{"languageId":"plaintext"},"id":"c4283e9d"},"outputs":[],"source":["trainer1 = MultiTaskTrainer(\n","    model           = model,\n","    args            = args1,\n","    train_dataset   = cls_ds,\n","    data_collator   = collate,\n",")\n","trainer1.train()\n","trainer1.save_model(\"stage1_cls_ckpt\")"]},{"cell_type":"code","execution_count":null,"id":"94c00100","metadata":{"vscode":{"languageId":"plaintext"},"id":"94c00100"},"outputs":[],"source":["class JointTrainer(MultiTaskTrainer):\n","    def compute_loss(\n","        self,\n","        model,\n","        inputs,\n","        return_outputs: bool = False,\n","        **kwargs\n","    ):\n","        outputs = model(\n","            **inputs,\n","            lambda_cls=1.0,\n","            lambda_gen=1.0\n","        )\n","        loss = outputs[\"loss\"]\n","        return (loss, outputs) if return_outputs else loss\n","full_ds = encoded_train\n","args2 = TrainingArguments(\n","    \"./stage2_joint\",\n","    per_device_train_batch_size=4, gradient_accumulation_steps=8,\n","    num_train_epochs=4, learning_rate=5e-5,\n","    logging_steps=100, fp16=True, report_to=\"none\",\n","    save_safetensors  = False, save_strategy     = \"no\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"f0c654ec","metadata":{"vscode":{"languageId":"plaintext"},"id":"f0c654ec"},"outputs":[],"source":["trainer2 = JointTrainer(\n","    model           = model,\n","    args            = args2,\n","    train_dataset   = full_ds,\n","    data_collator   = collate,\n",")\n","trainer2.train()\n","trainer2.save_model(\"./drive/MyDrive/model/stage2_joint_ckpt\")"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}